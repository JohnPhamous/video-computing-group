webpackJsonp([0],{"+VW6":function(a,t,e){"use strict";t.a={data:function(){return{title:"People",facultyMembers:[{name:"Amit Roy-Chowdhury",position:"Professor, Electrical and Computer Engineering",image:"amit.jpg",website:"",contact:{email:"amitrc@ee.ucr.edu",mobile:"951-827-7886",website:"/"}}],undergrads:[{name:"Cody Simons",position:"Undergraduate Student, Electrical and Computer Engineering",image:"cody.jpg",website:"",contact:{email:"csimo005@ucr.edu",mobile:"",website:""}}],grads:[{name:"Jawadul H. Bappy",position:"PhD Candidate, Electrical and Computer Engineering",image:"jawad.png",website:"http://www.ee.ucr.edu/~mbappy/",contact:{email:"mbapp001@ucr.edu",mobile:"951-827-7886",website:"http://www.ee.ucr.edu/~mbappy/"}},{name:"Akash Gupta",position:"PhD Candidate, Electrical and Computer Engineering",image:"Akash.jpg",website:"",contact:{email:"",mobile:"",website:""}},{name:"Sasha Li",position:"",image:"shasha.jpg",website:"",contact:{email:"",mobile:"",website:""}},{name:"Shuyue Lan",position:"PhD Student, Electrical and Computer Engineering",image:"shuyue.jpg",website:"",contact:{email:"slan001@ucr.edu",mobile:"",website:"http://www.ee.ucr.edu/~slan/"}},{name:"Amit Roy-sssChowdhury",position:"PhD Candidate, Electrical and Computer Engineering",image:"tahmida2.jpg",website:"",contact:{email:"tmahm001@ucr.edu",mobile:"",website:"https://sites.google.com/site/tahmidamahmud/"}},{name:"Niluthpol Mithun",position:"PhD Student, Electrical and Computer Engineering",image:"Mithun.jpg",website:"",contact:{email:"nmith001@ucr.edu",mobile:"",website:"http://www.ee.ucr.edu/~nmithun/"}},{name:"Rameswar Panda",position:"PhD Student, Electrical and Computer Engineering",image:"Panda.png",website:"",contact:{email:"rpand002@ucr.edu",mobile:"",website:"https://rpand002.github.io/"}},{name:"Sujoy Paul",position:"PhD Candiate, Electrical and Computer Engineering",image:"sujoy.jpg",website:"",contact:{email:"supaul@ece.ucr.edu",mobile:"",website:"http://ee.ucr.edu/~supaul/"}},{name:"Sourya Roy",position:"PhD Candidate, Electrical and Compouting Engineering",image:"sourya.jpg",website:"",contact:{email:"souroy099@gmail.com ",mobile:"",website:""}}]}}}},"+YSy":function(a,t,e){"use strict";var i=e("hXCR"),n=e("pBMn"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},"0sUC":function(a,t,e){"use strict";var i=e("yVyP"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},"1OOY":function(a,t,e){a.exports=e.p+"static/img/neh.9f16007.svg"},"1Shb":function(a,t,e){"use strict";var i=e("K7ZM"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},"5ZaB":function(a,t,e){a.exports=e.p+"static/img/ucr-logo.7db66ff.png"},"7A/x":function(a,t,e){a.exports=e.p+"static/img/image4.4638a1c.png"},"8EWh":function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,i=a._self._c||t;return i("div",{attrs:{id:"header-amit"}},[i("router-link",{attrs:{to:"/"}},[i("div",{attrs:{id:"header"}},[i("div",{staticClass:"row inherit-height"},[i("div",{staticClass:"col-md-1 col-xs-2 inherit-height"},[i("img",{staticClass:"img-fluid vc",attrs:{id:"ucr-logo",src:e("5ZaB"),alt:"UCR's Logo"}})]),a._v(" "),i("div",{staticClass:"col-md-11 col-xs-10 inherit-height",attrs:{id:"header-title"}},[i("p",{staticClass:"vc"},[i("span",{staticClass:"primary no-margin h2"},[a._v("Video Computing Group")]),a._v(" "),i("br"),a._v("\n                      Developing the Premier Computing Vision Algorithms\n                  ")])])])])])],1)},n=[],s={render:i,staticRenderFns:n};t.a=s},Dd1x:function(a,t,e){a.exports=e.p+"static/img/google.4414115.png"},E5uT:function(a,t,e){"use strict";t.a={name:"publications",data:function(){return{books:[{name:"Camera Networks: The Acquisition and Analysis of Videos Over Wide Areas",note:"A. Roy-Chowdhury and B. Song. Morgan and Claypool (Synthesis Lectures in Computer Vision), 2012.",link:"http://www.morganclaypool.com/doi/abs/10.2200/S00400ED1V01Y201201COV004"},{name:"Distributed Video Sensor Networks",note:"Eds. B. Bhanu, C. Ravishankar, A. Roy-Chowdhury, H. Aghajan, D. Terzopoulos. Springer, 2010.",link:"http://www.springer.com/computer/image+processing/book/978-0-85729-126-4"},{name:"Recognition of Humans and Their Activities Using Video",note:"R. Chellappa, A. Roy-Chowdhury, S. Zhou. Morgan and Claypool (Synthesis Lectures in Image, Video, & Multimedia Processing), 2005.",link:"http://www.amazon.com/gp/product/1598290061/qid=1134776125/sr=1-1/ref=sr_1_1/104-3732392-4137503?s=books&v=glance&n=283155"}],articles:[{name:"Joint Prediction of Activity Labels and Starting Times in Untrimmed Videos",note:"T. Mahmud, M. Hasan and A. Roy-Chowdhury, International Conference on Computer Vision, 2017.",link:"static/publications/ICCV_Tahmida.pdf",year:"2017"},{name:"Exploiting Spatial Structure for Localizing Manipulated Image Regions",note:"J. H. Bappy, A. Roy-Chowdhury, J. Bunk, L. Nataraj and B. S. Manjunath, International Conference on Computer Vision, 2017.",link:"static/publications/ICCV_Jawad.pdf",year:"2017"},{name:"Weakly Supervised Summarization of Web Videos",note:"R. Panda, A. Das, Z. Wu, J. Ernst and A. Roy-Chowdhury, International Conference on Computer Vision, 2017.",link:"static/publications/ICCV_Jawad.pdf",year:"2017"},{name:"Diversity-aware Multi-Video Summarization",note:"R. Panda, N. C. Mithun and A. Roy-Chowdhury, IEEE Trans. on Image Processing, 2017.",link:"static/publications/TIP_Rameswar.pdf",extras:[{name:"Supplemental Material",path:"static/publications/TIP_Supp_Rameswar.pdf"}],year:"2017"},{name:"Multi-View Surveillance Video Summarization via Joint Embedding and Sparse Optimization",note:"R. Panda and A. Roy-Chowdhury, IEEE Trans. on Multimedia, 2017.",link:"static/publications/TMM_Rameswar.pdf",year:"2017"},{name:"Detection and Localization of Image Forgeries using Resampling Features and Deep Learning",note:"J. Bunk, J. H. Bappy, T. M. Mohammed, L. Nataraj, A. Flenner, B.S. Manjunath, S. Chandrasekaran, A. Roy-Chowdhury and L. Peterson, IEEE Conf. on Computer Vision and Pattern Recognition Workshop, 2017.",link:"static/publications/CVPR_Workshop_Jawad.pdf",year:"2017"},{name:"Unsupervised Adaptive Re-identification in Open World Dynamic Camera Networks",note:"R. Panda, A. H. Bhuiyan, V. Murino and A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2017 (Spotlight).",link:"static/publications/cvpr2017reid.pdf",year:"2017"},{name:"Collaborative Summarization of Topic-Related Videos",note:"R. Panda and A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2017.",link:"static/publications/cvpr2017summ.pdf",year:"2017"},{name:"Non-Uniform Subset Selection for Active Learning in Structured Data",note:"S. Paul, J. H. Bappy, A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2017.",link:"static/publications/cvpr2017subset.pdf",year:"2017"},{name:"The Impact of Typicality for Informative Representative Selection",note:"J. H. Bappy, S. Paul, E. Tuncel and A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2017.",link:"static/publications/cvpr2017typicality.pdf",year:"2017"},{name:"Continuous adaptation of multi-camera person identification models through sparse non-redundant representative selection",note:"A. Das, R. Panda, A. Roy-Chowdhury, Computer Vision and Image Understanding, 2016.",link:"static/publications/CVIU_2016_Abir.pdf",extras:[{name:"Supplemental Material",path:"static/publications/Supplementary_CVIU_2016_Abir.pdf"}],year:"2016"},{name:"Distributed Multi-target Tracking and Data Association in Vision Networks",note:"A. T. Kamal, J. H. Bappy, J. A. Farrell, A. Roy-Chowdhury, IEEE Trans. on Pattern Analysis and Machine Intelligence, 2016.",link:"static/publications/MTIC-TPAMI.pdf",extras:[{name:"Code",path:"static/publications/MTIC_Matlab_Code.zip"}],year:"2016"},{name:"Network Consistent Data Association",note:"A. Chakraborty, A. Das, A. Roy-Chowdhury, IEEE Trans. on Pattern Analysis and Machine Intelligence, 2016.",link:"static/publications/Camera_Ready_Manuscript.pdf",extras:[{name:"Supplemental Material",path:"static/publications/supp_NCDA.pdf"},{name:"Code",path:"static/publications/NCDA_Code.zip"}],year:"2016"},{name:"Online Adaptation for Joint Scene and Object Classification",note:"J. H. Bappy, S. Paul, A. Roy-Chowdhury, European Conf. on Computer Vision, 2016.",link:"static/publications/eccv2016_jawad.pdf",year:"2016"},{name:"Temporal Model Adaptation for Person Re-Identification",note:"N. Martinel, C. Micheloni, A. Roy-Chowdhury, European Conf. on Computer Vision, 2016.",link:"static/publications/niki-eccv16.pdf",year:"2016"},{name:"Context-Aware Video Summarization",note:"S. Zhang, Y. Zhu, A. Roy-Chowdhury, IEEE Trans. on Image Processing, 2016.",link:"static/publications/TIP2016_summarization.pdf",year:"2016"},{name:"Learning Temporal Regularity in Video Sequences",note:"M. Hasan, J. Choi, J. Neumann, A. Roy-Chowdhury, and L. Davis, IEEE Conf. on Computer Vision and Pattern Recognition, 2016.",link:"static/publications/cvpr2016_regularity.pdf",extras:[{name:"Code",path:"static/publications/regularity.html"}],year:"2016"},{name:"Opportunistic Image Acquisition of Individual and Group Activities in a Distributed Camera Network",note:"C. Ding, J. H. Bappy, J. A. Farrell, A. Roy-Chowdhury, IEEE Transactions on Circuits and Systems for Video Technology, 2016.",link:"static/publications/TCSVT_2016.pdf",year:"2016"},{name:"Generating Diverse Image Datasets with Limited Labeling",note:"N. C. Mithun, R. Panda, A. Roy-Chowdhury, ACM International Conf. on Multimedia, 2016.",link:"static/publications/ACM_2016.pdf",year:"2016"},{name:"Incremental Learning of Human Activity Models from Videos",note:"M. Hasan, and A. Roy-Chowdhury, Computer Vision and Image Understanding, 2016.",link:"static/publications/2016_cviu.pdf",extras:[{name:"Code",path:"static/publications/incremental.html"}],year:"2016"},{name:"Optimal Landmark Selection for Registration of 4D Confocal Image Stacks in Arabidopsis",note:"K. Mkrtchyan, A. Chakraborty, and A. Roy-Chowdhury, IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2016.",link:"static/publications/TCBB.pdf",year:"2016"},{name:"Video Summarization in a Multi-View Camera Network",note:"R. Panda, A. Das, A. Roy-Chowdhury, International Conf. on Pattern Recognition, 2016.",link:"static/publications/ICPR_Rameswar.pdf",year:"2016"},{name:"Inter-dependent CNNs for Joint Scene and Object Recognition",note:"J. H. Bappy, A. Roy-Chowdhury, International Conf. on Pattern Recognition, 2016.",link:"static/publications/ICPR2016_SO_Jawad.pdf",year:"2016"},{name:"A Poisson Process Model for Activity Forecasting",note:"T. Mahmud, M. Hasan, A. Chakraborty, A. Roy-Chowdhury, IEEE International Conf. on Image Processing, 2016.",link:"static/publications/icip2016_timeforecast.pdf",year:"2016"},{name:"Efficient Selection of Informative and Diverse Training Samples with Applications in Scene Classification",note:"S. Paul, J. H. Bappy, A. Roy-Chowdhury, IEEE International Conf. on Image Processing, 2016.",link:"static/publications/icip2016_trainingsampleselection.pdf",year:"2016"},{name:"Adaptive Algorithm Selection, with Applications in Pedestrian Detection",note:"S. Zhang, Q. Zhu, A. Roy-Chowdhury, IEEE International Conf. on Image Processing, 2016.",link:"static/publications/icip2016_pedestrian.pdf",year:"2016"},{name:"Context Aware Active Learning of Activity Recognition Models",note:"M. Hasan, A. Roy-Chowdhury, International Conference on Computer Vision, 2015.",link:"static/publications/ICCV2015.pdf",extras:[{name:"Code",path:"static/publications/caal.html"}],year:"2015"},{name:"A Continuous Learning Framework for Activity Recognition Using Deep Hybrid Feature Models",note:"M. Hasan, A. Roy-Chowdhury, IEEE Trans. on Multimedia, 2015.",link:"static/publications/tmm2015.pdf",extras:[{name:"Code",path:"static/publications/hybrid.html"}],year:"2015"},{name:"Re-Identification in the Function Space of Feature Warps",note:"A. Das, N. Martinel, C. Micheloni, A. Roy-Chowdhury, IEEE Trans. on Pattern Analysis and Machine Intelligence, 2015.",link:"static/publications/PAMI14-Reid.pdf",extras:[{name:"Supplemental Material",path:"static/publications/Supplementary-PAMI2014-Reid.pdf"}],year:"2015"},{name:"Context-Aware Activity Modeling using Hierarchical Conditional Random Fields",note:"Y. Zhu, N. Nayak, A. Roy-Chowdhury, IEEE Trans. on Pattern Analysis and Machine Intelligence, 2015.",link:"static/publications/PAMI14-Activity.pdf",extras:[{name:"Code",path:"static/publications/download.html"}],year:"2015"},{name:"Computerized Face Recognition in Renaissance Portrait Art",note:"R. Srinivasan, C. Rudolph, and A. K. Roy-Chowdhury, Signal Processing Magazine. 2015.",link:"static/publications/spm2015.pdf",extras:[{name:"Supplmental Material",path:"static/publications/SPM2015_SM.pdf"}],year:"2015"},{name:"Tracking multiple interacting targets in a camera network",note:"S. Zhang, Y. Zhu, and A. K. Roy-Chowdhury, Computer Vision and Image Understanding special issue on Image Understanding for Real-world Distributed Video Networks. 2015.",link:"static/publications/Shu CVIU final.pdf",year:"2015"},{name:"Hierarchical Graphical Models for Simultaneous Tracking and Recognition in Wide-Area Scenes",note:"N. M. Nayak, Y. Zhu, and A. K. Roy-Chowdhury, IEEE Transactions on Image Processing, 2015.",link:"static/publications/tip_twocolumn_revised.pdf",year:"2015"},{name:"A Camera Network Tracking (CamNet) Dataset and Performance Baseline",note:"S. Zhang, E. Staudt, T. Faltemier, A. Roy-Chowdhury, IEEE Winter Conference on Applications of Computer Vision, 2015.",link:"egpaper_final.pdf",extras:[{name:"CamNeT Dataset",path:"static/publications/0B7uDdIqGrZlVfmdlOFZyUEg3RHUxaUdSaGVGTTNDT3R0dUNLSFdCSkZYVWk0dE16TFg4cTA.html"}],year:"2015"},{name:"Context Aware Spatio-temporal Cell Tracking In Densely Packed Multilayer Tissues",note:"A. Chakraborty, A. Roy-Chowdhury, Medical Image Analysis, 2014.",link:"static/publications/MedIA-14.pdf",extras:[{name:"Supplemental Material",path:"static/publications/MedIA-Supplementary.pdf"},{name:"Code",path:"static/publications/Context-CRF-Tracker.zip"}],year:"2014"},{name:"Context-Aware Activity Forecasting",note:"A. Chakraborty, A. Roy-Chowdhury, Asian Conf. on Computer Vision, 2014.",link:"static/publications/ACCV_2014.pdf",extras:[],year:"2014"},{name:"Consistent Re-identification In A Camera Network",note:"A. Das, A. Chakraborty, A. Roy-Chowdhury, European Conf. on Computer Vision, 2014.",link:"static/publications/eccv2014-2.pdf",extras:[{name:"Supplemental Material",path:"static/publications/NCR_ECCV2014_Supplementary.pdf"},{name:"Code",path:"static/publications/NCR_Code.html"}],year:"2014"},{name:"Continuous Learning of Human Activity Models Using Deep Nets",note:"M. Hasan, A. Roy-Chowdhury, European Conf. on Computer Vision, 2014.",link:"static/publications/eccv2014-1.pdf",extras:[{name:"Code",path:"static/publications/hybrid (1).html"}],year:"2014"},{name:"Incremental Activity Modeling and Recognition in Streaming Videos",note:"M. Hasan, A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2014.",link:"static/publications/cvpr2014.pdf",extras:[],year:"2014"},{name:"Learning A Sparse Dictionary of Video Structure for Activity Modeling",note:"N. Nayak, A. Roy-Chowdhury, IEEE Intl. Conf. on Image Processing, 2014.",link:"static/publications/icip2014.pdf",extras:[],year:"2014"},{name:"Distributed Constrained Optimization for Bayesian Opportunistic Visual Sensing",note:"A. Morye, C. Ding, J. A. Farrell, A. Roy-Chowdhury, IEEE Trans. on Control Systems Technology, 2014.",link:"static/publications/akshay_tcst.pdf",extras:[],year:"2014"},{name:"Managing Redundant Content in Bandwidth Constrained Wireless Networks",note:"T. Dao, S. Krishnamurthy, A. Roy-Chowdhury, T. LaPorta, International Conf. on emerging Networking EXperiments and Technologies, 2014.",link:"static/publications/conext_2014.pdf",extras:[],year:"2014"},{name:"Exploiting Spatio-Temporal Scene Structure for Wide-Area Activity Analysis in Unconstrained Environments",note:"N. Nayak, Y. Zhu, A. Roy-Chowdhury, IEEE Trans. on Information Forensics and Security (Special Issue on Intelligent Video Surveillance), 2013.",link:"static/publications/tifs_context.pdf",extras:[],year:"2013"},{name:"Information Weighted Consensus Filters and their Application in Distributed Camera Networks",note:"A. Kamal, J. A. Farrell, A. Roy-Chowdhury, IEEE Trans. on Automatic Control, 2013.",link:"static/publications/ICF_TAC.pdf",extras:[{name:"Code",path:"static/publications/ICF_Matlab_Code.zip"}],year:"2013"},{name:"Context-Aware Modeling and Recognition of Activities in Video",note:"Y. Zhu, N. Nayak, A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2013 (Oral).",link:"static/publications/cvpr2013_context.pdf",extras:[{name:"Code",path:"static/publications/download (1).html"}],year:"2013"},{name:"Recognizing the Royals - Leveraging Computerized Face Recognition for Identifying Subjects in Ancient Artworks",note:"R. Srinivasan, A. Roy-Chowdhury, C. Rudolph, J. Kohl, ACM Intl. Conf. on Multimedia, 2013.",link:"static/publications/acm-mm2013.pdf",extras:[],year:"2013"},{name:"Information Consensus for Distributed Multi-Target Tracking",note:"A. Kamal, J. A. Farrell, A. Roy-Chowdhury, IEEE Conf. on Computer Vision and Pattern Recognition, 2013.",link:"static/publications/CVPR2013_MTIC.pdf",extras:[{name:"Supplemental Material",path:"static/publication/CVPR2013_MTIC_Supplementary.pdf"},{name:"Code",path:"static/publication/MTIC_Matlab_Code (1).zip"}],year:"2013"},{name:'Modeling Multi-object Interactions using "String of Feature Graphs"',note:"Y. Zhu, N. Nayak, U. Gaur, B. Song, A. Roy-Chowdhury, Computer Vision and Image Understanding, 2013.",link:"static/publications/cviu13.pdf",extras:[],year:"2013"},{name:"Adaptive Geometric Tessellation For 3D Reconstruction of Anisotropically Developing Cells In Multilayer Tissues From Sparse Volumetric Microscopy Images",note:"A. Chakraborty, M. Perales, G. V. Reddy, A. Roy-Chowdhury, PLOS One, 2013.",link:"static/publications/article.html",extras:[],year:"2013"},{name:"Context-Aware Activity Recognition and Anomaly Detection in Video",note:"Y. Zhu, N. Nayak, A. Roy-Chowdhury, IEEE Journal on Selected Topics in Signal Processing, Special Issue on Anomalous Pattern Discovery, February 2013.",link:"static/publications/jstsp13.pdf",extras:[{name:"Code",path:"static/publications/download (2).html"}],year:"2013"},{name:"Vector Field Analysis for Multi-Object Behavior Modeling",note:"N. Nayak, Y. Zhu, A. Roy-Chowdhury, Image and Vision Computing, 2013.",link:"static/publications/N. Nayak, Y. Zhu, A. Roy-Chowdhury, Image and Vision Computing, 2013.",extras:[],year:"2013"},{name:"Quantitative Analysis of Live-Cell Growth at the Shoot Apex of Arabidopsis thaliana: Algorithms for Feature Measurement and Temporal alignment",note:"M. Tataw, V. Reddy, E. Keogh, A. Roy-Chowdhury, IEEE/ACM Trans. on Computational Biology and Biomedicine, 2013 (In Press).",link:"static/publications/tataw_tcbb_final.pdf",extras:[],year:"2013"},{name:"Automated Registration of Live Imaging Stacks of Arabidopsis",note:"K. Mkrtchyan, A. Chakraborty, A. Roy-Chowdhury, International Symposium on Biomedical Imaging, 2013.",link:"static/publications/isbi2013_Katya.pdf",extras:[],year:"2013"},{name:"Collaborative Sensing In A Distributed PTZ Camera Network",note:"C. Ding, B. Song, A. Morye, J. A. Farrell, A. Roy-Chowdhury, IEEE Trans. on Image Processing, 2012.",link:"static/publications/tip_cding2012.pdf",extras:[],year:"2012"},{name:"Features with Feeling - Incorporating User Preferences in Video Categorization",note:"R. Srinivasan, A. Roy-Chowdhury, Asian Conference on Computer Vision, 2012.",link:"static/publications/accv-2012-final.pdf",extras:[],year:"2012"},{name:"Information Weighted Consensus",note:"A. Kamal, J. A. Farrell, A. Roy-Chowdhury, IEEE Controls and Decision Conf., 2012.",link:"static/publications/CDC_2012.pdf",extras:[{name:"Code",path:"static/publications/CameraNetworks.php"}],year:"2012"},{name:"Alignment of Real-Time Live-Cell Growth Data for Quantitative Analysis of Growth at the Shoot Apex of Arabidopsis thaliana",note:"M. Tataw, V. Reddy, A. Roy-Chowdhury, ACM Conference on Bioinformatics, Computational Biology and Biomedicine, 2012.",link:"static/publications/publications.php",extras:[],year:"2012"},{name:"Opportunistic Sensing In A Distributed PTZ Camera Network",note:"C. Ding, A. Morye, J. A. Farrell, A. Roy-Chowdhury, IEEE Intl. Conf. on Distributed Smart Cameras, 2012.",link:"static/publications/icdsc2012.pdf",extras:[],year:"2012"},{name:"Coordinated Sensing and Tracking for Mobile Camera Platforms",note:"C. Ding, A. Morye, J. A. Farrell, A. Roy-Chowdhury, American Controls Conf., 2012.",link:"static/publications/ACC_2012.pdf",extras:[],year:"2012"},{name:"Integrated Sensing and Analysis for Wide Area Scene Understanding",note:"B. Song, C. Ding, A. Kamal, J. Farrell, A. Roy-Chowdhury, Signal Processing Magazine, May 2011.",link:"static/publications/SPM_camnetwork.pdf",extras:[],year:"2011"},{name:"A Physics-Based Analysis of Image Appearance Models",note:"Y. Xu, A. Roy-Chowdhury, IEEE Trans. on Pattern Analysis and Machine Intelligence, August 2011.",link:"static/publications/PAMI_2011.pdf",extras:[{name:"Supplemental Material",path:"static/publication/SupplementaryMaterial_PAMI2011.pdf"}],year:"2011"},{name:'A "String of Feature Graphs" Model for Recognition of Complex Activities in Natural Videos',note:"U. Gaur, Y. Zhu, B. Song, A. Roy-Chowdhury, IEEE Conf. on Computer Vision, 2011.",link:"static/publications/iccv-SFG.pdf",extras:[],year:"2011"},{name:"Cell Resolution 3D Reconstruction of Developing Multilayer Tissues from Sparsely Sampled Volumetric Microscopy Images",note:"A. Chakraborty, R. Yadav, G. V. Reddy, A. Roy-Chowdhury, IEEE Intl. Conf. on Bioinformatics and Biomedicine, 2011.",link:"static/publications/bibm11-anirban.pdf",extras:[],year:"2011"},{name:"A Large-scale Benchmark Dataset for Event Recognition in Surveillance Video",note:"Sangmin Oh, Anthony Hoogs, Amitha Perera, Naresh Cuntoor, C.-C. Chen, Jong Taek Lee, Saurajit Mukherjee, J. K. Aggarwal, Hyungtae Lee, Larry Davis, Eran Swears, Xioyang Wang, Qiang Ji, Kishore Reddy, Mubarak Shah, Carl Vondrick, Hamed Pirsiavash, Deva Ramanan, Jenny Yuen, Antonio Torralba, Bi Song, Anesco Fong, Amit Roy-Chowdhury, and Mita Desai, IEEE Conf. on Computer Vision and Pattern Recognition, 2011.",link:"static/publications/cvpr2011.pdf",extras:[],year:"2011"},{name:"Adaptive Cell Segmentation and Tracking for Volumetric Confocal Microscopy Images of A Developing Plant Meristem",note:"M. Liu, A. Chakraborty, D. Singh, M. Gopi, R. Yadav, G.V. Reddy, and A. Roy-Chowdhury, Molecular Plant, 2011.",link:"static/publications/tracking-molplant.pdf",extras:[],year:"2011"},{name:"Motion Pattern Analysis for Modeling and Recognition of Complex Human Activities",note:"N. Nayak, R. Sethi, B. Song, A. Roy-Chowdhury, in Guide to Video Analysis of Humans: Looking at People (Eds., T. Moeslund, A. Hilton, V. Kruger, L. Sigal), Springer 2011.",link:"static/publications/Activity_chapter_nandita.pdf",extras:[],year:"2011"},{name:"Robust Wide Area Tracking in Single and Multiple Views",note:"B. Song, R. Sethi, A. Roy-Chowdhury, in Guide to Video Analysis of Humans: Looking at People (Eds., T. Moeslund, A. Hilton, V. Kruger, L. Sigal), Springer 2011",link:"static/publications/LAPbook_tracking.pdf",extras:[],year:"2011"},{name:"A Generalized Kalman Consensus Filter for Wide Area Video Networks",note:"A. Kamal, C. Ding, B. Song, J. A. Farrell, A. Roy-Chowdhury, Controls and Decision Conference, 2011.",link:"static/publications/cdc11.pdf",extras:[],year:"2011"},{name:"",note:"",link:"static/publications/",extras:[],year:"2010"},{name:"",note:"",link:"static/publications/",extras:[],year:"2009"},{name:"",note:"",link:"static/publications/",extras:[],year:"2008"},{name:"",note:"",link:"static/publications/",extras:[],year:"2007"},{name:"",note:"",link:"static/publications/",extras:[],year:"2006"},{name:"",note:"",link:"static/publications/",extras:[],year:"2005"},{name:"",note:"",link:"static/publications/",extras:[],year:"2004"},{name:"",note:"",link:"static/publications/",extras:[],year:"2003"}]}}}},Fs8J:function(a,t,e){"use strict";var i=e("OiVu"),n=e("IeM7"),s=e("0sUC"),o=e("OBbp");t.a={components:{AmitHomeBody:i.a,NewsAmit:n.a,PromoImagesAmit:s.a,Sponsors:o.a},name:"AmitHeader"}},G6e4:function(a,t,e){"use strict";var i=e("E5uT"),n=e("Zyqw"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},GPKu:function(a,t,e){"use strict";var i=e("hlG1"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},IeM7:function(a,t,e){"use strict";var i=e("UWUf"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},JeFR:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,i=a._self._c||t;return i("div",{staticClass:"row text-center",attrs:{id:"sponsors"}},[i("h3",[a._v("Acknowledgements")]),a._v(" "),i("p",[a._v("The Video Computing Group graciously acknowledges the funding received from a number of government agencies and private corporations.")]),a._v(" "),i("div",{staticClass:"col-md-1 col-md-offset-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("gqVA"),alt:"AFOSR"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("MjAs"),alt:"ARO"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("Muom"),alt:"CISCO"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("xq7R"),alt:"DARPA"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("Dd1x"),alt:"Google"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("lGGH"),alt:"Lockheed Martin"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("l+Fy"),alt:"Mayachitra"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("1OOY"),alt:"NEH"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("seTK"),alt:"NGA"}})])]),a._v(" "),i("div",{staticClass:"col-md-1"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("X6+c"),alt:"NSF"}})])])])}],s={render:i,staticRenderFns:n};t.a=s},K7ZM:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"inherit-height",attrs:{id:"data"}},[e("div",{attrs:{id:"home-body"}},[e("div",{staticClass:"container row"},[e("div",{staticClass:"col-md-6 dataset"},[e("h2",[a._v("Videoweb Activities Dataset")]),a._v(" "),e("p",[a._v("The Videoweb Activities Dataset has about 2.5 hours of video data consisting of dozens of activities along with annotation. The data is now available publicly for research. Please download and submit the following release form to gain access to the dataset. Below are some samples from the data.")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"../../static/datasets/RELEASE_OF_VIDEWEB_ACTIVITIES_DATASET.pdf"}},[a._v("Release Form")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"https://svn.engr.ucr.edu/vcSVN/VideoWebData"}},[a._v("Login to Videoweb Activities Dataset")]),a._v(" "),e("p",[e("strong",[a._v("Please refer to the following article when using this dataset:")]),e("br"),a._v(" "),e("small",[a._v('G. Denina, B. Bhanu, H. Nguyen, C. Ding, A. Kamal, C. Ravishankar, A. Roy-Chowdhury, A. Ivers, and B. Varda, "VideoWeb Dataset for Multi-camera Activities and Non-verbal Communication", in Distributed Video Sensor Networks (Eds. B. Bhanu, C. Ravishankar, A. Roy-Chowdhury, H. Aghajan, D. Terzopoulos), Springer 2010.\n              This data collection was partially supported by the Aware Building project under ONR-N00014-07-C-0311 and ARO grant W911NF-07-1-0485.')])]),a._v(" "),e("a",{staticClass:"btn btn-info",attrs:{href:"../../static/datasets/scene1.mpg"}},[a._v("Sample Scene 1")]),a._v(" "),e("a",{staticClass:"btn btn-info",attrs:{href:"../../static/datasets/scene2.mpg"}},[a._v("Sample Scene 2")]),a._v(" "),e("a",{staticClass:"btn btn-info",attrs:{href:"../../static/datasets/scene3.mpg"}},[a._v("Sample Scene 3")]),a._v(" "),e("a",{staticClass:"btn btn-info",attrs:{href:"../../static/datasets/scene4.mpg"}},[a._v("Sample Scene 4")])]),a._v(" "),e("div",{staticClass:"col-md-6 dataset"},[e("h2",[a._v("Re-identification Across indoor-outdoor Dataset (RAiD)")]),a._v(" "),e("p",[a._v("This person re-identification dataset was collected at the Winstun Chung Hall of UC Riverside. It is a 4 camera dataset with 2 indoor and 2 outdoor cameras. The cameras are numbered as 1,2,3 and 4 where cameras 1 and 2 are indoor while cameras 3 and 4 are outdoor. 43 people walked in these camera views resulting in 6920 images. Among the 43 persons 41 people appeared in all the 4 cmareas where as person 8 is not present in camera 3 and person 34 is not present in camera 4.")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"http://cs-people.bu.edu/dasabir/raid.php"}},[a._v("Dataset")]),a._v(" "),e("p",[e("strong",[a._v("Please refer to the following article when using this dataset:")]),e("br"),a._v(" "),e("small",[a._v('\n                      A. Das, A. Chakraborty, A. Roy-Chowdhury."Consistent Re-identification In A Camera Network". European Conference on Computer Vision, pp. 330-345, vol.8690, Zurich, 2014.\n                  ')])])])]),a._v(" "),e("div",{staticClass:"container row"},[e("div",{staticClass:"col-md-6 dataset"},[e("h2",[a._v("Camera Network Tracking Dataset (CamNeT)")]),a._v(" "),e("p",[a._v("CamNeT is a non-overlapping camera network dataset that is designed for tracking. The dataset is composed of five to eight cameras covering both indoor and outdoor scenes at University of California, Riverside. This dataset consists of six scenarios. Within each scenario are challenges relevant to lighting changes, complex topographies, crowded scenes, and changing grouping dynamics. Persons with predefined trajectories are combined with persons with random trajectories. A baseline multi-target tracking system and its results are provided.")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"https://drive.google.com/open?id=0B7uDdIqGrZlVfmdlOFZyUEg3RHUxaUdSaGVGTTNDT3R0dUNLSFdCSkZYVWk0dE16TFg4cTA&authuser=0"}},[a._v("Dataset")]),a._v(" "),e("p",[e("strong",[a._v("Please refer to the following article when using this dataset:")]),e("br"),a._v(" "),e("small",[a._v('S. Zhang, E. Staudt, T. Faltemier, A. Roy-Chowdhury. "A Camera Network Tracking (CamNeT) Dataset and Performance Baseline". In IEEE Winter Conference on Applications of Computer Vision, Waikoloa Beach, Hawaii, January, 2015.')])])]),a._v(" "),e("div",{staticClass:"col-md-6 dataset"},[e("h2",[a._v("Tour20 Video Summarization Dataset")]),a._v(" "),e("p",[a._v("Tour20 is a video summarization dataset that is designed primarily for multi-video summarization. However, it can also be used for evaluating single-video summarization in a repeatable and efficient way. It contains 140 videos of total 6 hour 46 minutes duration that are downloaded from YouTube with creative commons license, CC-By 3.0. The dataset consists of three human created ground truth summaries for each of the videos as well as a diverse set of summary to describe the video collection of a tourist place. We also provide the shot segmentation files that indicate the shot boundary transitions of each video.")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"https://drive.google.com/file/d/0B3uIyPMHSpNrSzk5QWc3WnBwT3c/view?pref=2&pli=1"}},[a._v("Dataset")]),a._v(" "),e("p",[e("strong",[a._v("Please refer to the following article when using this dataset:")]),e("br"),a._v(" "),e("small",[a._v('\n                      A. Das, A. Chakraborty, A. Roy-Chowdhury."Consistent Re-identification In A Camera Network". European Conference on Computer Vision, pp. 330-345, vol.8690, Zurich, 2014.\n                  ')])])])]),a._v(" "),e("div",{staticClass:"container row"},[e("div",{staticClass:"col-md-6 dataset"},[e("h2",[a._v("DivNet Image Dataset")]),a._v(" "),e("p",[a._v("The DivNet dataset contains images for around 550 object and scene categories, averaging around 1K images per category. The categories are mainly chosen from ILSVRC2016 object detection and scene classification challenge. The images for each category were originally collected from Google, Bing and Flickr. The collected images has been refined in a semi-supervised incremental sparse-coding framework, so that a high-quality image dataset can be created with limited human labeling. We release images, which were originally crawled with Creative Commons license (CC-By 3.0) for non-commercial reuse.")]),a._v(" "),e("a",{staticClass:"btn btn-primary",attrs:{href:"https://drive.google.com/drive/folders/0Bznxmj1nmRUjSC1LSzE0aTctUzA"}},[a._v("Dataset")]),a._v(" "),e("p",[e("strong",[a._v("Please refer to the following article when using this dataset:")]),e("br"),a._v(" "),e("small",[a._v('N. C. Mithun, R. Panda and A. K. Roy-Chowdhury, "Generating Diverse Image Datasets with Limited Labeling" in ACM MM, Amsterdam, October, 2016.')])])])])])])}],s={render:i,staticRenderFns:n};t.a=s},M93x:function(a,t,e){"use strict";var i=e("xJD8"),n=e("djTn"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},MjAs:function(a,t,e){a.exports=e.p+"static/img/aro.6ae0755.gif"},Muom:function(a,t,e){a.exports=e.p+"static/img/cisco.1ebec25.png"},NHnr:function(a,t,e){"use strict";Object.defineProperty(t,"__esModule",{value:!0});var i=e("7+uW"),n=e("M93x"),s=e("YaEn"),o=e("O0Ew"),r=e("+YSy"),c=e("GPKu");i.a.component("Header",o.a),i.a.component("Nav",r.a),i.a.component("Footer",c.a),i.a.config.productionTip=!1,new i.a({el:"#app",router:s.a,template:"<App/>",components:{App:n.a}})},O0Ew:function(a,t,e){"use strict";var i=e("vaqm"),n=e("8EWh"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},OBbp:function(a,t,e){"use strict";var i=e("JeFR"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},OiVu:function(a,t,e){"use strict";var i=e("iY3p"),n=e("VU/8"),s=n(null,i.a,null,null,null);t.a=s.exports},R6fH:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"inherit-height"},[e("div",{attrs:{id:"home-body"}},[e("PromoImagesAmit"),a._v(" "),e("AmitHomeBody"),a._v(" "),e("NewsAmit"),a._v(" "),e("Sponsors")],1)])},n=[],s={render:i,staticRenderFns:n};t.a=s},UWUf:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,i=a._self._c||t;return i("div",{staticClass:"row container"},[i("div",{staticClass:"col-md-3"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("cZ8c"),alt:""}})]),a._v(" "),i("a",{attrs:{href:"#"}},[a._v("\n           Diversity-aware Multi-Video Summarization\n         ")])]),a._v(" "),i("div",{staticClass:"col-md-3"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("cZ8c"),alt:""}})]),a._v(" "),i("a",{attrs:{href:"#"}},[a._v("\n           Diversity-aware Multi-Video Summarization\n         ")])]),a._v(" "),i("div",{staticClass:"col-md-3"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("cZ8c"),alt:""}})]),a._v(" "),i("a",{attrs:{href:"#"}},[a._v("\n           Diversity-aware Multi-Video Summarization\n         ")])]),a._v(" "),i("div",{staticClass:"col-md-3"},[i("a",{attrs:{href:"#"}},[i("img",{staticClass:"news",attrs:{src:e("cZ8c"),alt:""}})]),a._v(" "),i("a",{attrs:{href:"#"}},[a._v("\n           Diversity-aware Multi-Video Summarization\n         ")])])])}],s={render:i,staticRenderFns:n};t.a=s},"X6+c":function(a,t,e){a.exports=e.p+"static/img/nsf.94d4b47.png"},Xy5h:function(a,t,e){a.exports=e.p+"static/img/image5.bb7892c.png"},YaEn:function(a,t,e){"use strict";var i=e("7+uW"),n=e("/ocq"),s=e("lO7g"),o=e("1Shb"),r=e("G6e4"),c=e("gJEX");i.a.use(n.a),t.a=new n.a({routes:[{path:"/",name:"Home",component:s.a},{path:"/datasets",name:"Datasets",component:o.a},{path:"/publications",name:"Publications",component:r.a},{path:"/people",name:"PeopleHome",component:c.a}],mode:"history"})},Zyqw:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"inherit-height",attrs:{id:"data"}},[e("div",{attrs:{id:"home-body"}},[e("div",{staticClass:"container row"},[e("div",{staticClass:"col-md-12"},[a._m(0),a._v(" "),e("div",{staticClass:"alert alert-danger",attrs:{role:"alert"}},[a._v("The contributing authors include the documents contained in these directories as a means to ensure timely dissemination of scholarly and technical work on a non-commercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author's copyright. These works may not be reposted without the explicit permission of the copyright holder.")]),a._v(" "),e("div",{staticClass:"panel panel-primary"},[a._m(1),a._v(" "),e("ul",{staticClass:"list-group"},a._l(a.books,function(t){return e("li",{key:t.name,staticClass:"list-group-item"},[e("a",{attrs:{href:t.link}},[e("h3",[a._v(a._s(t.name))]),a._v(" "),e("p",[e("small",[a._v(a._s(t.note))])])])])}))]),a._v(" "),e("div",{staticClass:"panel panel-primary"},[a._m(2),a._v(" "),e("ul",{staticClass:"list-group"},a._l(a.articles,function(t){return e("li",{key:t.name,staticClass:"list-group-item"},[e("span",{staticClass:"badge"},[a._v("Published in "+a._s(t.year))]),a._v(" "),e("a",{attrs:{href:t.link}},[e("h3",[a._v(a._s(t.name))]),a._v(" "),e("p",[e("small",[a._v(a._s(t.note))])])]),a._v(" "),void 0!==t.extras?e("div",{staticClass:"extraContainer"},a._l(t.extras,function(t){return e("a",{key:t.path,staticClass:"btn btn-primary",attrs:{href:t.path}},[a._v(a._s(t.name))])})):a._e()])}))])])])])])},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("p",[e("small")])},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"panel-heading"},[e("h3",{staticClass:"panel-title"},[a._v("Books and Edited Books")])])},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"panel-heading"},[e("h3",{staticClass:"panel-title"},[a._v("Publications")])])}],s={render:i,staticRenderFns:n};t.a=s},cZ8c:function(a,t,e){a.exports=e.p+"static/img/image3.e20f56f.png"},djTn:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"container inherit-height",attrs:{id:"app"}},[e("Header"),a._v(" "),e("Nav"),a._v(" "),e("router-view"),a._v(" "),e("Footer")],1)},n=[],s={render:i,staticRenderFns:n};t.a=s},gJEX:function(a,t,e){"use strict";var i=e("+VW6"),n=e("jxC1"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},gqVA:function(a,t,e){a.exports=e.p+"static/img/afosr.820f17c.png"},hXCR:function(a,t,e){"use strict";t.a={name:"NavAmit",data:function(){return{navItems:[{name:"Home",link:"/"},{name:"Publications",link:"/publications"},{name:"Datasets",link:"/datasets"},{name:"People",link:"/people"}]}}}},hlG1:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("footer",{staticClass:"footer"},[e("div",{staticClass:"container text-center"},[e("div",{staticClass:"row",staticStyle:{"margin-top":"25px"}},[e("div",{staticClass:"col-md-12"},[e("p",{staticClass:"text-muted"},[a._v("\n           Department of Electrical and Computer Engineering"),e("br"),a._v("\n           University of California, Riverside"),e("br"),a._v("\n           Copyright Â© 2017 Video Computing Group\n         ")])])])])])}],s={render:i,staticRenderFns:n};t.a=s},iY3p:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"home-body"},[e("div",{staticClass:"row"},[e("div",{staticClass:"col-md-8"},[e("h3",[a._v("\n           The Video Computing Group at UC Riverside conducts cutting edge research in computer vision, image processing, pattern recognition, statistical learning, and statistical processing.\n         ")]),a._v(" "),e("p",[a._v("\n           Current projects are related to camera networks, human activity recognition and recognition, and bioimage analysis. The work provides the scientific underpinning behind applications capable of automated/semi-automated analysis of the 3D environment from images/videos, analogous to capabilities of biological visual systems. Members of the group regularly publish in top-tier conferences and journals in computer vision and image processing. Past members work in major research labs and hold faculty positions across the world.\n         ")])]),a._v(" "),e("div",{staticClass:"col-md-4"},[e("h3",[a._v("\n           Open Positions\n         ")]),a._v(" "),e("p",[a._v("\n           If you are interested in a position feel free to contact Dr. Amit Chowdhury\n         ")]),a._v(" "),e("ul",[e("li",[a._v("Undergraduates")]),a._v(" "),e("li",[a._v("Graduates")]),a._v(" "),e("li",[a._v("Post-Doc")])])])]),a._v(" "),e("hr")])}],s={render:i,staticRenderFns:n};t.a=s},jxC1:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"inherit-height",attrs:{id:"data"}},[e("div",{attrs:{id:"home-body"}},[e("div",{staticClass:"container row"},[a._m(0),a._v(" "),e("div",{staticClass:"col-md-6"},[e("div",{staticClass:"row"},a._l(a.facultyMembers,function(t){return e("div",{key:t.name,staticClass:"person"},[e("div",{key:t.name,staticClass:"col-md-3"},[e("img",{staticClass:"img-responsive",attrs:{src:"static/img/people/"+t.image}})]),a._v(" "),e("div",{staticClass:"col-md-9"},[e("h4",[e("strong",[a._v(a._s(t.name))])]),a._v(" "),e("p",[e("strong",[a._v(a._s(t.position))])]),a._v(" "),t.contact.mobile.length>0?e("p",{attrs:{disabled:""}},[e("span",{staticClass:"fa fa-phone"}),a._v(" "+a._s(t.contact.mobile))]):a._e()]),a._v(" "),e("div",{staticClass:"col-md-12 personActions"},[t.contact.email.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:"mailto:"+t.contact.email}},[e("span",{staticClass:"fa fa-envelope-o"}),a._v(" Email")]):a._e(),a._v(" "),t.contact.website.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:t.contact.website}},[e("span",{staticClass:"fa fa-globe"}),a._v(" Website")]):a._e()])])}))])]),a._v(" "),e("div",{staticClass:"container row"},[a._m(1),a._v(" "),a._l(a.grads,function(t){return e("div",{key:t.name,staticClass:"col-md-6 personContainer"},[e("div",{staticClass:"row"},[e("div",{staticClass:"person"},[e("div",{key:t.name,staticClass:"col-md-3"},[e("img",{staticClass:"img-responsive",attrs:{src:"static/img/people/"+t.image}})]),a._v(" "),e("div",{staticClass:"col-md-9"},[e("h4",[e("strong",[a._v(a._s(t.name))])]),a._v(" "),e("p",[e("strong",[a._v(a._s(t.position))])]),a._v(" "),t.contact.mobile.length>0?e("p",{attrs:{disabled:""}},[e("span",{staticClass:"fa fa-phone"}),a._v(" "+a._s(t.contact.mobile))]):a._e()]),a._v(" "),e("div",{staticClass:"col-md-12 personActions"},[t.contact.email.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:"mailto:"+t.contact.email}},[e("span",{staticClass:"fa fa-envelope-o"}),a._v(" Email")]):a._e(),a._v(" "),t.contact.website.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:t.contact.website}},[e("span",{staticClass:"fa fa-globe"}),a._v(" Website")]):a._e()])])])])})],2),a._v(" "),e("div",{staticClass:"container row"},[a._m(2),a._v(" "),a._l(a.undergrads,function(t){return e("div",{key:t.name,staticClass:"col-md-6 personContainer"},[e("div",{staticClass:"row"},[e("div",{staticClass:"person"},[e("div",{key:t.name,staticClass:"col-md-3"},[e("img",{staticClass:"img-responsive",attrs:{src:"static/img/people/"+t.image}})]),a._v(" "),e("div",{staticClass:"col-md-9"},[e("h4",[e("strong",[a._v(a._s(t.name))])]),a._v(" "),e("p",[e("strong",[a._v(a._s(t.position))])]),a._v(" "),t.contact.mobile.length>0?e("p",{attrs:{disabled:""}},[e("span",{staticClass:"fa fa-phone"}),a._v(" "+a._s(t.contact.mobile))]):a._e()]),a._v(" "),e("div",{staticClass:"col-md-12 personActions"},[t.contact.email.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:"mailto:"+t.contact.email}},[e("span",{staticClass:"fa fa-envelope-o"}),a._v(" Email")]):a._e(),a._v(" "),t.contact.website.length>0?e("a",{staticClass:"btn btn-primary btn-sm",attrs:{href:t.contact.website}},[e("span",{staticClass:"fa fa-globe"}),a._v(" Website")]):a._e()])])])])})],2)])])},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"col-md-12 text-center"},[e("h2",[a._v("Faculty Members")])])},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"col-md-12 text-center"},[e("h2",[a._v("Graduate Students")])])},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"col-md-12 text-center"},[e("h2",[a._v("Undergradute Students")])])}],s={render:i,staticRenderFns:n};t.a=s},"l+Fy":function(a,t,e){a.exports=e.p+"static/img/mayachitra.d83a5f0.png"},lGGH:function(a,t,e){a.exports=e.p+"static/img/lockheed.e5a6c9a.png"},lO7g:function(a,t,e){"use strict";var i=e("Fs8J"),n=e("R6fH"),s=e("VU/8"),o=s(i.a,n.a,null,null,null);t.a=o.exports},lY1t:function(a,t,e){a.exports=e.p+"static/img/amitrc_cover.bc92ac1.jpg"},pBMn:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("nav",{staticClass:"navbar navbar-default"},[e("div",{staticClass:"container-fluid"},[a._m(0),a._v(" "),e("div",{staticClass:"collapse navbar-collapse",attrs:{id:"bs-example-navbar-collapse-1"}},[e("ul",{staticClass:"nav navbar-nav"},[a._l(a.navItems,function(t){return e("li",[e("router-link",{attrs:{to:t.link}},[a._v(a._s(t.name))])],1)}),a._v(" "),a._m(1)],2)])])])},n=[function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("div",{staticClass:"navbar-header"},[e("button",{staticClass:"navbar-toggle collapsed",attrs:{type:"button","data-toggle":"collapse","data-target":"#bs-example-navbar-collapse-1","aria-expanded":"false"}},[e("span",{staticClass:"sr-only"},[a._v("Toggle navigation")]),a._v(" "),e("span",{staticClass:"icon-bar"}),a._v(" "),e("span",{staticClass:"icon-bar"}),a._v(" "),e("span",{staticClass:"icon-bar"})])])},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("li",{staticClass:"dropdown"},[e("a",{staticClass:"dropdown-toggle",attrs:{href:"#","data-toggle":"dropdown",role:"button","aria-haspopup":"true","aria-expanded":"false"}},[a._v("Research Projects"),e("span",{staticClass:"caret"})]),a._v(" "),e("ul",{staticClass:"dropdown-menu"},[e("li",[e("a",{attrs:{href:"#"}},[a._v("Overview")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Human Robot Vision Network")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Wide Area Scene Analysis in Vision Network")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Activity Recognition and Prediction")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Situational Awareness Under Resource Constraints")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Face Tracking and Recognition")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Biological Image Analysis")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("VideoWeb: A Video Network Lab")])]),a._v(" "),e("li",[e("a",{attrs:{href:"#"}},[a._v("Multi-Terminal Video Compression")])])])])}],s={render:i,staticRenderFns:n};t.a=s},seTK:function(a,t,e){a.exports=e.p+"static/img/nga.544bb7f.png"},vaqm:function(a,t,e){"use strict";t.a={name:"HeaderAmit"}},xJD8:function(a,t,e){"use strict";t.a={name:"app"}},xq7R:function(a,t,e){a.exports=e.p+"static/img/dapra.f5f14b2.png"},yVyP:function(a,t,e){"use strict";var i=function(){var a=this,t=a.$createElement;a._self._c;return a._m(0)},n=[function(){var a=this,t=a.$createElement,i=a._self._c||t;return i("div",{staticClass:"row header-parent"},[i("div",{staticClass:"col-md-3 header-img-container"},[i("img",{staticClass:"header-img",attrs:{src:e("lY1t"),alt:"The Team"}})]),a._v(" "),i("div",{staticClass:"col-md-3 header-img-container"},[i("img",{staticClass:"header-img",attrs:{src:e("cZ8c"),alt:""}})]),a._v(" "),i("div",{staticClass:"col-md-3 header-img-container"},[i("img",{staticClass:"header-img",attrs:{src:e("7A/x"),alt:""}})]),a._v(" "),i("div",{staticClass:"col-md-3 header-img-container"},[i("img",{staticClass:"header-img",attrs:{src:e("Xy5h"),alt:""}})])])}],s={render:i,staticRenderFns:n};t.a=s}},["NHnr"]);
//# sourceMappingURL=app.ee02b545f643120cdd14.js.map